{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setting up the python env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #  python -m venv env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Installing necessary libraries\n",
    "    - numpy\n",
    "    - seaborn\n",
    "    - matplotlib\n",
    "    - scikit-learn\n",
    "    - pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Learn how to use Jupyter in Vs Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Finding Dataset\n",
    "    - kaggle: https://www.kaggle.com/datasets\n",
    "    - UCI: https://archive.ics.uci.edu/datasets\n",
    "    - google dataset: https://datasetsearch.research.google.com/\n",
    "    - USA dataset: [data.gov](https://data.gov/)\n",
    "    - Paper with code: https://paperswithcode.com/datasets\n",
    "    - Harrvard dataset: https://dataverse.harvard.edu/dataverse/harvard/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading csv using pandas\n",
    "import pandas as pd\n",
    "dataset_dir = \"../dataset/Ecommerce Customers.csv\"\n",
    "df = pd.read_csv(dataset_dir)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading image with pillow\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "folder_path = '../dataset/Chess Dataset'\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for subfolder_name in os.listdir(folder_path):\n",
    "    subfolder_path = os.path.join(folder_path, subfolder_name)\n",
    "    \n",
    "    if os.path.isdir(subfolder_path):\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                img_path = os.path.join(subfolder_path, filename)\n",
    "                img = Image.open(img_path)\n",
    "                images.append(img)\n",
    "                labels.append(subfolder_name)\n",
    "\n",
    "print(\"Loaded Images: \", len(images))\n",
    "print(\"Labels: \", labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading image using OpenCV\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "folder_path = '../dataset/Chess Dataset'\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for subfolder_name in os.listdir(folder_path):\n",
    "    subfolder_path = os.path.join(folder_path, subfolder_name)\n",
    "    \n",
    "    if os.path.isdir(subfolder_path):\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                img_path = os.path.join(subfolder_path, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None: \n",
    "                    images.append(img)\n",
    "                    labels.append(subfolder_name)\n",
    "\n",
    "print(\"Loaded Images: \", len(images))\n",
    "print(\"Labels: \", labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading image using pytorch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder('../dataset/Chess Dataset', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "iter_image = 100\n",
    "print(f\"Image {iter_image+1}: Label {dataset[iter_image][1]}, Class Name: {dataset.classes[dataset[iter_image][1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore csv file\n",
    "print(\"type of df: \", type(df))\n",
    "print(\"lenght df: \", len(df))\n",
    "print(\"shape df: \", df.shape)\n",
    "\n",
    "# print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update cell in dataframe\n",
    "df.at[0, 'Time on App'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing basics statistic\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count by None value\n",
    "df['Address'].isna().sum() # ISNA method return where values repaced true for NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count by condition\n",
    "df[df['Avatar'] == 'DarkGreen'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing record that Missing\n",
    "df.dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Missing Data (Imputation)\n",
    "df.fillna(df.mean(numeric_only=True)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Min-Max Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "pd.DataFrame(\n",
    "    scaler.fit_transform(\n",
    "        df[['Avg. Session Length', 'Time on App','Time on Website', 'Length of Membership', 'Yearly Amount Spent']]), \n",
    "        columns=['Avg. Session Length', 'Time on App','Time on Website', 'Length of Membership', 'Yearly Amount Spent']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset using scikit learn package\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership']]\n",
    "y = df[['Yearly Amount Spent']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
